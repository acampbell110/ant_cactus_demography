---
title: "Tester"
author: "Ali Campbell"
date: "12/28/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Create the data:
```{r}
library(MASS) # For multivariate normal distribution, handy later on
n <- 50
set.seed(18050518)
dat <- data.frame(xc = rnorm(n), xb = rbinom(n, 1, .5))

dat <- within(dat, y <- rpois(n, exp(.5 * xc + xb)))
summary(dat)
```

Model:
```{r}
mod <- glm(y ~ xc + xb, poisson, dat)
```

Simulated Data:
```{r}
coefs <- mvrnorm(n = 10000, mu = coefficients(mod), Sigma = vcov(mod))
```

Check this against original model
```{r}
#Simulated Coefficients
colMeans(coefs)
#Original Coefficients
coefficients(mod)
```
These are pretty similar, so I will now look at standard errors

```{r}
#Simulated Standard Error
apply(coefs, 2, sd)
#Original Standard Error
sqrt(diag(vcov(mod)))
```
These are also pretty good. So now we simulate the data

```{r}
#simulate the data
sim.dat <- matrix(nrow = n, ncol = nrow(coefs))
mod.mat <- model.matrix(mod)
for (i in 1:nrow(coefs)) {
  sim.dat[, i] <- rpois(n, exp(mod.mat %*% coefs[i, ]))
}
rm(i, mod.mat)
```

Now we compare the simualted and original variance and mean
```{r}
#Simulated mean and var
c(mean(colMeans(sim.dat)), mean(apply(sim.dat, 2, var)))
#Original mean and var
c(mean(dat$y), var(dat$y))
```
These are pretty close, particularly teh means


###Now try this same process with the growth model that is just a glm
Model:
```{r}
grow_model
```

Simulated Data:
```{r}
coefs <- mvrnorm(n = 10000, mu = coefficients(grow_model), Sigma = vcov(grow_model))
```

Check this against original model
```{r}
#Simulated Coefficients
colMeans(coefs)
#Original Coefficients
coefficients(grow_model)
```
These are pretty similar, so I will now look at standard errors

```{r}
#Simulated Standard Error
apply(coefs, 2, sd)
#Original Standard Error
sqrt(diag(vcov(grow_model)))
```
These are also pretty good. So now we simulate the data

```{r}
#simulate the data
sim.dat <- matrix(nrow = n, ncol = nrow(coefs))
mod.mat <- model.matrix(grow_model)
for (i in 1:nrow(coefs)) {
  sim.dat[, i] <- rpois(n, exp(mod.mat %*% coefs[i, ]))
}
rm(i, mod.mat)
```

Now we compare the simualted and original variance and mean
```{r}
#Simulated mean and var
c(mean(colMeans(sim.dat)), mean(apply(sim.dat, 2, var)))
#Original mean and var
c(mean(cactus$volume_t1,na.rm=TRUE), var(cactus$volume_t1,na.rm = TRUE))
```

This mean is not close, but the variances are not THAT bad. We know though that this model is not good. 

###Try again with the right growth model
Model:
```{r}
grow_model_ant_interact
```

Simulated Data:
```{r}
coefs <- mvrnorm(n = 10000, mu = coefficients(grow_model_ant_interact), Sigma = vcov(grow_model_ant_interact))
```

Check this against original model
```{r}
#Simulated Coefficients
colMeans(coefs)
#Original Coefficients
coefficients(grow_model_ant_interact)
```
These are pretty similar, so I will now look at standard errors

```{r}
#Simulated Standard Error
apply(coefs, 2, sd)
#Original Standard Error
sqrt(diag(vcov(grow_model_ant_interact)))
```
These are also pretty good. So now we simulate the data

```{r}
#simulate the data
sim.dat <- matrix(nrow = n, ncol = nrow(coefs))
mod.mat <- model.matrix(grow_model_ant_interact)
for (i in 1:nrow(coefs)) {
  sim.dat[, i] <- rpois(n, exp(mod.mat %*% coefs[i, ]))
}
rm(i, mod.mat)
```

Now we compare the simualted and original variance and mean
```{r}
#Simulated mean and var
c(mean(colMeans(sim.dat)), mean(apply(sim.dat, 2, var)))
#Original mean and var
c(mean(cactus$volume_t1,na.rm=TRUE), var(cactus$volume_t1,na.rm = TRUE))
```

The variance is not that far off
The mean is significantly different. This to me indicates that likely the model is not a good one



###Now Josh's Method

```{r}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyverse)
library(lme4)
library(nnet)
library(fixest)
library(mlogit)
library(dfidx)
library(effects)
library(bbmle)
library(magrittr)
library(Gmisc)
library(RColorBrewer)
library(ggeffects)
library(heplots)
require(lattice)
elvi_fitness_data <- read.csv("/Users/alicampbell/Desktop/endo_herb_georef.csv", header = TRUE,stringsAsFactors=T)
```


```{r}
# This is were I run the model
# This is a gaussian model, but you can change the family to be poisson or whatever
infl_mod <- glm(mean_infl_length ~ year*Endo_status_liberal, data = (subset(elvi_fitness_data)), family = "gaussian")
anova(infl_mod, test = "Chisq")
summary(infl_mod)

# plot(infl_mod)

# This is our simulated predictor data
newdat1<- data.frame(year = seq(1900,2016,1), Endo_status_liberal = 1)
newdat0 <- data.frame(year= seq(1900,2016,1), Endo_status_liberal = 0)
newdat <- rbind(newdat0, newdat1)

# use the predict function for to get the model output
y_pred <- predict(infl_mod, newdata = newdat, type = "response")
y_CI <- predict(infl_mod, newdata = newdat, interval = "confidence", type = "link", se.fit=TRUE)

#This is one way to pull out the link function automatically from the fitted object
linkinv <- family(infl_mod)$linkinv ## inverse-link function

# you can also define your own link function, which is useful for stuff like Stan, where you just get posterior draws, and not a R model object
# and so for my other project, where I have categorical data, I define these functions at the top of the script
# invlogit<-function(x){exp(x)/(1+exp(x))}
# and then use that transform the model predictions to the appropriate scale
# I think for poisson, you can use exp() to exponentiate the results

#Now make a dataframe that combines all the predictions and confidence intervals
newpred <- newdat
newpred$pred0 <- y_CI$fit
newpred$pred <- linkinv(y_CI$fit) #This is the link function
alpha <- 0.95
sc <- abs(qnorm((1-alpha)/2))  ## Normal approx. to likelihood
alpha2 <- 0.5
sc2 <- abs(qnorm((1-alpha2)/2))  ## Normal approx. to likelihood
newpred <- transform(newpred,
                     lwr=linkinv(pred0-sc*y_CI$se.fit),
                     upr=linkinv(pred0+sc*y_CI$se.fit),
                     lwr2=linkinv(pred0-sc2*y_CI$se.fit),
                     upr2=linkinv(pred0+sc2*y_CI$se.fit))

# Then you can plot it
ELVI_outcomeyear <- ggplot() +
  geom_point(data = elvi_fitness_data, aes(x = year, y =mean_infl_length, pch = as.factor(Endo_status_liberal)), color = "#4c90dd", lwd = 2)+
  geom_line(data = newpred, aes(x = year, y = pred, group = Endo_status_liberal, linetype = as.factor(Endo_status_liberal)), color = "#4c90dd") +
  geom_ribbon(data = newpred, aes(x = year, ymin = lwr, ymax = upr, group = Endo_status_liberal, fill = as.factor(Endo_status_liberal)), alpha = .2) +
  theme_classic() + labs(y = "Mean Inflorescence Length", x = "Year", linetype = "Endophyte_status", shape = "Endophyte_status")+
  scale_linetype_manual(breaks = c("1", "0"),
                        values = c("solid", "dashed"))+
  scale_shape_manual(breaks = c("1", "0"),
                     values = c(20,1))+
  scale_fill_manual(breaks = c("1", "0"),
                    values = c(  "#4c90dd", "#636363")) +
  xlim(1910,2016) + guides(fill = FALSE)

ELVI_outcomeyear
#ggsave(ELVI_outcome, filename = "~/Documents/ELVIinflyear.tiff", width = 4, height = 3)
```

```{r}
# This is were I run the model
# This is a gaussian model, but you can change the family to be poisson or whatever
surv_model_ant_interact
anova(surv_model_ant_interact, test = "Chisq")
summary(surv_model_ant_interact)
# plot(infl_mod)

# This is our simulated predictor data
min(cactus$volume_t, na.rm = T)
newdat1<- data.frame(volume_t = seq(log(0.1),log(3129321),0.002076463), ant_t = "crem")
newdat2 <- data.frame(volume_t= seq(log(0.1),log(3129321),0.002076463), ant_t = "liom")
newdat3 <- data.frame(volume_t= seq(log(0.1),log(3129321),0.002076463), ant_t = "vacant")
newdat4 <- data.frame(volume_t= seq(log(0.1),log(3129321),0.002076463), ant_t = "other")
newdat <- rbind(newdat1, newdat1, newdat2, newdat3)

# use the predict function for to get the model output
y_pred <- predict(surv_model_ant_interact, newdata = newdat, type = "response")
y_CI <- predict(surv_model_ant_interact, newdata = newdat, interval = "confidence", type = "link", se.fit=TRUE)

#This is one way to pull out the link function automatically from the fitted object
linkinv <- family(surv_model_ant_interact)$linkinv ## inverse-link function

# you can also define your own link function, which is useful for stuff like Stan, where you just get posterior draws, and not a R model object
# and so for my other project, where I have categorical data, I define these functions at the top of the script
invlogit<-function(x){exp(x)/(1+exp(x))}
# and then use that transform the model predictions to the appropriate scale
# I think for poisson, you can use exp() to exponentiate the results

#Now make a dataframe that combines all the predictions and confidence intervals
newpred <- newdat
newpred$pred0 <- y_CI$fit
newpred$pred <- invlogit(y_CI$fit) #This is the link function
alpha <- 0.95
sc <- abs(qnorm((1-alpha)/2))  ## Normal approx. to likelihood
alpha2 <- 0.5
sc2 <- abs(qnorm((1-alpha2)/2))  ## Normal approx. to likelihood
newpred <- transform(newpred,
                     lwr=invlogit(pred0-sc*y_CI$se.fit),
                     upr=invlogit(pred0+sc*y_CI$se.fit),
                     lwr2=invlogit(pred0-sc2*y_CI$se.fit),
                     upr2=invlogit(pred0+sc2*y_CI$se.fit))

# Then you can plot it
ggplot() + 
  geom_point(data = cactus, aes(x = log(volume_t), y = Survival_t1, pch = as.factor(ant_t)), color = "#4c90dd", lwd = 2) + 
  geom_line(data = newpred, aes(x = volume_t, y = pred, group = ant_t, linetype = as.factor(ant_t))) +
  geom_ribbon(data = newpred, aes(x = volume_t, ymin = lwr, ymax = upr, group = ant_t, fill = as.factor(ant_t)), alpha = .2) + 
  geom_smooth(data=cactus, aes(y=Survival_t1, x=log(volume_t), col=ant_t), method = "glm", formula='y~x', method.args = list(family = "binomial"), se = TRUE)
  #geom_smooth(data = cactus, aes(x = log(volume_t), y = Survival_t1, pch = as.factor(ant_t)))
```

```{r}
# This is were I run the model
# This is a gaussian model, but you can change the family to be poisson or whatever
surv_model_ant_interact
anova(surv_model_ant_interact, test = "Chisq")
summary(surv_model_ant_interact)
# plot(infl_mod)

# This is our simulated predictor data
min(cactus$volume_t, na.rm = T)
newdat1<- data.frame(volume_t = seq(log(0.1),log(3129321),0.002076463), ant_t = "crem")
newdat2 <- data.frame(volume_t= seq(log(0.1),log(3129321),0.002076463), ant_t = "liom")
newdat3 <- data.frame(volume_t= seq(log(0.1),log(3129321),0.002076463), ant_t = "vacant")
newdat4 <- data.frame(volume_t= seq(log(0.1),log(3129321),0.002076463), ant_t = "other")
newdat <- rbind(newdat1, newdat1, newdat2, newdat3)

# use the predict function for to get the model output
y_pred <- predict(surv_model, newdata = newdat, type = "response")
y_CI <- predict(surv_model, newdata = newdat, interval = "confidence", type = "link", se.fit=TRUE)

#This is one way to pull out the link function automatically from the fitted object
linkinv <- family(surv_model_ant_interact)$linkinv ## inverse-link function

# you can also define your own link function, which is useful for stuff like Stan, where you just get posterior draws, and not a R model object
# and so for my other project, where I have categorical data, I define these functions at the top of the script
# invlogit<-function(x){exp(x)/(1+exp(x))}
# and then use that transform the model predictions to the appropriate scale
# I think for poisson, you can use exp() to exponentiate the results

#Now make a dataframe that combines all the predictions and confidence intervals
newpred <- newdat
newpred$pred0 <- y_CI$fit
newpred$pred <- linkinv(y_CI$fit) #This is the link function
alpha <- 0.95
sc <- abs(qnorm((1-alpha)/2))  ## Normal approx. to likelihood
alpha2 <- 0.5
sc2 <- abs(qnorm((1-alpha2)/2))  ## Normal approx. to likelihood
newpred <- transform(newpred,
                     lwr=linkinv(pred0-sc*y_CI$se.fit),
                     upr=linkinv(pred0+sc*y_CI$se.fit),
                     lwr2=linkinv(pred0-sc2*y_CI$se.fit),
                     upr2=linkinv(pred0+sc2*y_CI$se.fit))

# Then you can plot it
ggplot() + 
  geom_point(data = cactus, aes(x = log(volume_t), y = Survival_t1, pch = as.factor(ant_t)), color = "#4c90dd", lwd = 2) + 
  geom_line(data = newpred, aes(x = volume_t, y = pred, group = ant_t, linetype = as.factor(ant_t))) +
  geom_ribbon(data = newpred, aes(x = volume_t, ymin = lwr, ymax = upr, group = ant_t, fill = as.factor(ant_t)), alpha = .2) + 
  geom_smooth(data=cactus, aes(y=Survival_t1, x=log(volume_t), col=ant_t), method = "glm", formula='y~x', method.args = list(family = "binomial"), se = TRUE)
  #geom_smooth(data = cactus, aes(x = log(volume_t), y = Survival_t1, pch = as.factor(ant_t)))
```

Ok, so it appears that this follows the general trend, sort of. 

```{r}
ELVI_outcomeyear <- ggplot() +
  geom_point(data = cactus, aes(x = volume_t, y =Survival_t1, pch = as.factor(ant_t)), color = "#4c90dd", lwd = 2)+
  geom_line(data = newpred, aes(x = volume_t, y = pred, group = ant_t, linetype = as.factor(ant_t)), color = "#4c90dd") +
  geom_ribbon(data = newpred, aes(x = volume_t, ymin = lwr, ymax = upr, group = ant_t, fill = as.factor(ant_t)), alpha = .2) +
  theme_classic() + labs(y = "Mean Inflorescence Length", x = "Year", linetype = "Endophyte_status", shape = "Endophyte_status")+
  scale_linetype_manual(breaks = c("crem", "liom", "vacant", "other"),
                        values = c("solid", "dashed", "solid", "dashed"))+
  scale_shape_manual(breaks = c("crem", "liom", "vacant", "other"),
                     values = c(20,1))+
  scale_fill_manual(breaks = c("crem", "liom", "vacant", "other"),
                    values = c(  "#4c90dd", "#636363", "red", "green")) +
  xlim(1910,2016) + guides(fill = FALSE)

ELVI_outcomeyear
ggsave(ELVI_outcome, filename = "~/Documents/ELVIinflyear.tiff", width = 4, height = 3)
```